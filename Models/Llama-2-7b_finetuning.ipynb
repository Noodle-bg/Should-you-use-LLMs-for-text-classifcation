{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"60sa36AgeW0e"},"outputs":[],"source":["# Install Pytorch & other libraries\n","!pip install \"torch==2.1.2\" tensorboard\n","\n","# Install Hugging Face libraries\n","!pip install  --upgrade \\\n","  \"transformers==4.36.2\" \\\n","  \"datasets==2.16.1\" \\\n","  \"accelerate==0.26.1\" \\\n","  \"evaluate==0.4.1\" \\\n","  \"bitsandbytes==0.42.0\" \\\n","  \"trl==0.7.10\" # \\\n","  \"peft==0.7.1\" \\\n","\n","# # install peft & trl from github\n","# !pip install git+https://github.com/huggingface/trl@a3c5b7178ac4f65569975efadc97db2f3749c65e --upgrade\n","# !pip install git+https://github.com/huggingface/peft@4a1559582281fc3c9283892caea8ccef1d6f5a4f --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQ_mxMzi6KN2"},"outputs":[],"source":["# import required libraries\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from datasets import load_dataset\n","from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, BitsAndBytesConfig\n","\n","from transformers import AutoTokenizer\n","from trl import SFTTrainer , setup_chat_format\n","from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n","from sklearn.metrics import accuracy_score, classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Slx5Bqh2FeU"},"outputs":[],"source":["import torch; assert torch.cuda.get_device_capability()[0] >= 8, 'Hardware not supported for Flash Attention'\n","# install flash-attn\n","!pip install ninja packaging\n","!MAX_JOBS=4 pip install flash-attn --no-build-isolation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XSDxUomUn7qU"},"outputs":[],"source":["from huggingface_hub import login\n","login(\"lmao aint fooling me\",\n","      add_to_git_credential=True)\n","\n","\n","# Load the 20 Newsgroups dataset\n","dataset = load_dataset(\"SetFit/20_newsgroups\")\n","\n","# Split the dataset into train and test sets\n","train_data = dataset[\"train\"]\n","test_data = dataset[\"test\"]\n","\n","\n","\n","# Load the tokenizer\n","model_name = \"meta-llama/Llama-2-7b-hf\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=False)\n","tokenizer.padding_side = \"right\"\n","\n","\n","max_token_length = 480\n","\n","# Function to filter data by max token length\n","def filter_by_length(example):\n","    return len(tokenizer(example[\"text\"])[\"input_ids\"]) <= max_token_length\n","\n","# Apply filtering\n","train_data = train_data.filter(filter_by_length)\n","test_data = test_data.filter(filter_by_length)\n","train_data = train_data.select(range(3000))\n","test_data = test_data.select(range(1000))\n","\n","def make_prompt(example):\n","    categories_with_descriptions = \"\"\"\n","1. alt.atheism - Discussions about atheism and religious skepticism\n","2. comp.graphics - Computer graphics, rendering, and visualization\n","3. comp.os.ms-windows.misc - Microsoft Windows operating system topics\n","4. comp.sys.ibm.pc.hardware - IBM PC compatible hardware discussions\n","5. comp.sys.mac.hardware - Apple Macintosh hardware discussions\n","6. comp.windows.x - X-Windows system for Unix discussions\n","7. misc.forsale - Items for sale or wanted\n","8. rec.autos - Automobile enthusiasts' discussions\n","9. rec.motorcycles - Motorcycle enthusiasts' discussions\n","10. rec.sport.baseball - Baseball discussions and news\n","11. rec.sport.hockey - Hockey discussions and news\n","12. sci.crypt - Cryptography and encryption discussions\n","13. sci.electronics - Electronics theory and practice\n","14. sci.med - Medicine and health-related discussions\n","15. sci.space - Space exploration and astronomy\n","16. soc.religion.christian - Christian faith and practice discussions\n","17. talk.politics.guns - Firearms legislation and rights\n","18. talk.politics.mideast - Middle East politics and current events\n","19. talk.politics.misc - General political discussions\n","20. talk.religion.misc - Discussions about various religions\n","\"\"\"\n","\n","    icl_examples = \"\"\"\n","Example 1:\n","Text: The new Mars rover has successfully landed and begun its mission to search for signs of ancient microbial life.\n","Category: sci.space\n","\n","Example 2:\n","Text: I'm looking to upgrade my PC's graphics card. Any recommendations for a good mid-range option?\n","Category: comp.sys.ibm.pc.hardware\n","\n","Example 3:\n","Text: The First Amendment protects freedom of speech, but there are still ongoing debates about its limits in certain contexts.\n","Category: talk.politics.misc\n","\"\"\"\n","\n","    system_message = f\"\"\"You are a text classification expert. Your task is to classify the given text into one of the 20 newsgroup categories. The categories are:\n","\n","{categories_with_descriptions}\n","\n","Here are some examples of how to classify texts:\n","\n","{icl_examples}\n","\"\"\"\n","\n","    return{\n","    \"messages\": [\n","      {\"role\": \"system\", \"content\": system_message},\n","      {\"role\": \"user\", \"content\": example[\"text\"]},\n","      {\"role\": \"assistant\", \"content\": example[\"label_text\"]}\n","    ]\n","  }\n","\n","\n","\n","# Prepare the dataset\n","train_data = train_data.map(make_prompt, remove_columns=train_data.column_names)\n","test_data = test_data.map(make_prompt, remove_columns=test_data.column_names)\n","\n","print(f\"Filtered train data size: {len(train_data)}\")\n","print(f\"Filtered test data size: {len(test_data)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9eIXAp2ACeB"},"outputs":[],"source":["\n","train_data.to_json(\"train.json\",orient=\"records\")\n","test_data.to_json(\"test.json\",orient = \"records\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"Y2dMKj52cNcv"},"outputs":[],"source":["bnb_config = BitsAndBytesConfig(\n","    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",")\n","\n","# Load model and tokenizer\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    device_map=\"auto\",\n","    attn_implementation=\"flash_attention_2\",\n","    trust_remote_code=True,\n","    quantization_config=bnb_config,\n","\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"esunzK6050sY"},"outputs":[],"source":["model = prepare_model_for_kbit_training(model)\n","model.gradient_checkpointing_enable()\n","model, tokenizer = setup_chat_format(model, tokenizer)\n","\n","# Define LoRA Config\n","lora_config = LoraConfig(\n","    r=16,\n","    lora_alpha=32,\n","    target_modules=\"all-linear\", # Only the attention layers, can try including mlp\n","    lora_dropout=0.05,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\"\n",")\n","\n","# Get the PEFT model\n","model = get_peft_model(model, lora_config)\n","model.print_trainable_parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z_NCSnEKAj2w"},"outputs":[],"source":["from datasets import load_dataset\n","\n","# Load jsonl data from disk\n","train_data = load_dataset(\"json\", data_files=\"train.json\",split = \"train\")\n","test_data = load_dataset(\"json\", data_files=\"test.json\",split=\"train\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BZp0bQ8lAP1V"},"outputs":[],"source":["print(model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-AIwuT4XBmrn"},"outputs":[],"source":["print(test_data[\"messages\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iDqn0IOfex1Y"},"outputs":[],"source":["# !pip install torch==2.0.0+cu117\n","# !pip install pytorch-lightning==1.9.4\n","# !pip install accelerate==0.21.0\n","# !pip install tokenizers==0.13.3\n","# !pip install transformers==4.26.1\n","# import torch._dynamo\n","# torch._dynamo.config.suppress_errors = True\n","\n","# ! pip install wandb\n","# Set up training arguments\n","# For a resonable gpu\n","# training_args = TrainingArguments(\n","#     output_dir=\"./results\",\n","#     num_train_epochs=3,\n","#     per_device_train_batch_size=4,\n","#     gradient_accumulation_steps=4,\n","#     warmup_steps=100,\n","#     logging_dir=\"./logs\",\n","#     logging_steps=10,\n","#     save_strategy=\"epoch\",\n","#     learning_rate=2e-4,\n","#     fp16=True,\n","#     remove_unused_columns=False,\n","# )\n","# For this exp I am using the L4 GPU\n","from transformers import TrainingArguments\n","\n","torch.set_grad_enabled(True)\n","model.gradient_checkpointing_enable()\n","\n","# Set up training arguments\n","training_args = TrainingArguments(\n","    output_dir=\"./Llama-7b-hf-20_newsgroups_full\",\n","    num_train_epochs=3,\n","    per_device_train_batch_size=8,\n","    gradient_accumulation_steps=4,\n","    warmup_ratio=0.03,\n","    tf32=True,\n","    bf16=True,\n","    optim=\"adamw_torch\",\n","    max_grad_norm=0.3,\n","    logging_steps=10,\n","    save_strategy=\"steps\",\n","    save_steps=20,\n","    eval_steps=20,\n","    evaluation_strategy=\"steps\",\n","    dataloader_num_workers=2,\n","    group_by_length=True,\n","    report_to=\"tensorboard\",\n","    push_to_hub=True,\n","    hub_strategy=\"every_save\",\n","    hub_model_id=\"Noodle-bg/Llama-7b-hf_20_newsgroups_full\",\n","    gradient_checkpointing=True,)\n","\n","# Create SFT Trainer\n","max_seq_length = 1024\n","\n","trainer = SFTTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=train_data,\n","    peft_config=lora_config,\n","    tokenizer=tokenizer,\n","    max_seq_length=1024,\n","    packing=True,\n","    dataset_kwargs={\n","        \"add_special_tokens\": False,  # We template with special tokens\n","        \"append_concat_token\": False, # No need to add additional separator token\n","    },\n","\n","\n",")\n","\n","with torch.backends.cuda.sdp_kernel(enable_flash=True, enable_math=False, enable_mem_efficient=False):\n","    trainer.train()\n","\n","# Save the fine-tuned model\n","trainer.save_model(\"./Llama-7b-hf-20_newsgroups_full\")\n"]}],"metadata":{"colab":{"provenance":[],"mount_file_id":"1EBwfEqKbdo4cViSxdxY5D-I7jyTtScK0","authorship_tag":"ABX9TyMaUPDOkYpSnRsOOo7x3ug9"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}